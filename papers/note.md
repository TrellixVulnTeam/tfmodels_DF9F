##1、DeepFace
整个流程：人脸检测->人脸对齐->人脸表示/识别->人脸验证
###数据集：
1、在Facebook的SFC数据集上训练4030个人的多分类人脸识别任务，人均图片1k张，总共4m张图片的5%用作测试，错误率8%左右；
2、通过微调孪生网络(共享)预先训练的特征提取器来学习验证指标过程中，有大量的训练数据过拟合。使用LFW训练数据生成的训练对是冗余的，因为它们是从大约9K张照片中生成的，不足以可靠地估计超过1.2亿个参数。所以我们收集了一个与SFC相同程序的附加数据集，包含额外的10万个新人物，每个人物有30个样本，可从中生成相同和不相同的对。然后我们在此基础上对孪生网络进行训练。
3、在LFW数据集上微调，5.7k的名人照片采集6k对人脸，通过十折交叉进行训练和测试，ACC接近人类水平97%左右；
###模型
3D人脸对齐：
采用显式的3D人脸建模并应用分段仿射变换，并实现人脸正面化。DeepID和FaceNet并没有这种对齐，DeepID的解决方案是将一个人脸切成很多部分，每个部分都训练一个模型，然后模型聚合，FaceNet则是直接以数据量大和特殊的目标函数取胜。
人脸表示：
8层CNN网络学习多分类模型，最后一层长度为4096的隐藏层作为人脸的特征向量表示，输出层为softmax后的4030个人的概率；特征向量还做了归一化到0-1之间。
人脸验证：
对比了3种方法，无监督的直接利用特征向量的点积（余弦相似度cos=a⋅b/(|a|⋅|b|),就是向量归一化后的点积，只考虑角度，不考虑向量的长度）；
有监督的单核SVM和一层全连接的孪生网络；孪生网络直接去掉人脸表示模型的最后一层，复制两份并freeze，得到特征向量后求绝对值，最后直接分类为是否同一个人。
在目标任务上微调能够得到更好的效果，但是如果拟合的数据太小会导致泛化能力很差。
